{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "from pyproj import Proj\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Constants\n",
    "RAW_SEQ_LEN = 50\n",
    "PAD = 0\n",
    "K = 5\n",
    "DISTANCE_THRESHOLD = 100\n",
    "\n",
    "def split_indices_for_next_prediction(df):\n",
    "    grouped = df.groupby('agent').cumcount()\n",
    "    total_len = len(df)\n",
    "    train_end = int(total_len * 0.7)\n",
    "    val_end = int(total_len * 0.85)\n",
    "\n",
    "    train_indices = pd.DataFrame({'first_idx': range(0, train_end), 'last_idx': range(0, train_end)}).iloc[::RAW_SEQ_LEN]\n",
    "    val_indices = pd.DataFrame({'first_idx': range(train_end, val_end), 'last_index': range(train_end, val_end)}).iloc[::RAW_SEQ_LEN]\n",
    "    test_indices = pd.DataFrame({'first_idx': range(val_end, total_len), 'last_idx': range(val_end, total_len)}).iloc[::RAW_SEQ_LEN]\n",
    "\n",
    "    return train_indices, val_indices, test_indices\n",
    "\n",
    "# 1. Load the Data\n",
    "poi_cat_vecs_df = pd.read_parquet(\"/Users/mehul/Downloads/novateur.phase2.trial4/poi_cat_vecs.parquet\")\n",
    "poi_df = pd.read_csv(\"/Users/mehul/Downloads/novateur.phase2.trial4/poi.csv\")\n",
    "stay_poi_df = pd.read_parquet(\"/Users/mehul/Downloads/novateur.phase2.trial4/stay_poi_dfs/group=0/stay_poi.parquet\")\n",
    "\n",
    "# 2. Project Coordinates to UTM\n",
    "def project_to_utm(df, lat_col = 'latitude', lon_col = 'longitude'):\n",
    "    zone_number = int((df[lon_col].mean() + 180) // 6) + 1\n",
    "    utm_proj = Proj(proj='utm', zone=zone_number, ellps='WGS84')\n",
    "    df['x'], df['y'] = utm_proj(df[lon_col].values, df[lat_col].values)\n",
    "    return df\n",
    "\n",
    "stay_poi_df = project_to_utm(stay_poi_df, lat_col='latitude', lon_col='longitude')\n",
    "poi_df = project_to_utm(poi_df, lat_col='latitude', lon_col='longitude')\n",
    "\n",
    "# 3. Calculate Duration (in Hours)\n",
    "stay_poi_df['start_timestamp'] = pd.to_datetime(stay_poi_df['start_timestamp'])\n",
    "stay_poi_df['stop_timestamp'] = pd.to_datetime(stay_poi_df['stop_timestamp'])\n",
    "stay_poi_df['duration'] = (stay_poi_df['stop_timestamp'] - stay_poi_df['start_timestamp']).dt.total_seconds() / 3600\n",
    "\n",
    "# 4. Assign K nearest POIs from poi_df to each visit in stay_poi_df (create subset for POI attribution)\n",
    "poi_tree = cKDTree(poi_df[['x', 'y']].values)\n",
    "\n",
    "def find_candidate_pois(row):\n",
    "    \"\"\"Find the K nearest POIs within the distance threshold.\"\"\"\n",
    "    distances, indices = poi_tree.query([row['x'], row['y']], k=K, distance_upper_bound=DISTANCE_THRESHOLD)\n",
    "    valid_indices = indices[distances < DISTANCE_THRESHOLD]\n",
    "    if len(valid_indices) == 0:\n",
    "        return np.array([-1])  # Indicates no POIs within threshold\n",
    "    return poi_df.iloc[valid_indices]['poi_id'].values\n",
    "\n",
    "stay_poi_df['candidate_pois'] = stay_poi_df.apply(find_candidate_pois, axis=1)\n",
    "\n",
    "# 5. Map true POI to candidate index if poi_id exists in stay_poi_df\n",
    "if 'poi_id' in stay_poi_df.columns:\n",
    "    def get_true_index(row):\n",
    "        \"\"\"Map true poi_id to its index in candidate_pois.\"\"\"\n",
    "        if row['poi_id'] in row['candidate_pois']:\n",
    "            return list(row['candidate_pois']).index(row['poi_id'])\n",
    "        return -1  # True POI not in candidates\n",
    "    stay_poi_df['true_poi_index'] = stay_poi_df.apply(get_true_index, axis=1)\n",
    "\n",
    "# 6. Normalize time and compute travel time\n",
    "oldest_time = stay_poi_df['start_timestamp'].min()\n",
    "stay_poi_df['start_timestamp'] = (stay_poi_df['start_timestamp'] - oldest_time).dt.total_seconds() / (24 * 3600)  # Days\n",
    "stay_poi_df['stop_timestamp'] = (stay_poi_df['stop_timestamp'] - oldest_time).dt.total_seconds() / (24 * 3600)  # Days\n",
    "stay_poi_df['travel_time'] = stay_poi_df['start_timestamp'] - stay_poi_df['stop_timestamp'].shift(1).fillna(0)  # Days\n",
    "stay_poi_df.loc[stay_poi_df.groupby('agent').head(1).index, 'travel_time'] = 0  # Reset travel time for first visit per user\n",
    "\n",
    "# 7. Clip outliers\n",
    "max_duration = stay_poi_df['duration'].quantile(0.99)\n",
    "stay_poi_df.loc[stay_poi_df['duration'] > max_duration, 'duration'] = max_duration\n",
    "max_travel_time = stay_poi_df['travel_time'].quantile(0.99) * 24  # Convert to hours for clipping\n",
    "stay_poi_df.loc[stay_poi_df['travel_time'] * 24 > max_travel_time, 'travel_time'] = max_travel_time / 24\n",
    "\n",
    "# 8. Sort and split into sequences\n",
    "stay_poi_df.sort_values(by=['agent', 'start_timestamp'], inplace=True)\n",
    "train_indices, val_indices, test_indices = split_indices_for_next_prediction(stay_poi_df)\n",
    "\n",
    "# 9. Custom dataset classes\n",
    "class POIPredictionDataset(Dataset):\n",
    "    def __init__(self, df, indices):\n",
    "        self.df = df\n",
    "        self.indices = indices.astype(int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        first_idx, last_idx = self.indices.iloc[idx].values\n",
    "        instance = self.df.iloc[first_idx:last_idx + 1]\n",
    "        visits = instance[['x', 'y', 'start_timestamp', 'end_timestamp', 'duration', 'travel_time']].values\n",
    "        candidate_pois = np.stack(instance['candidate_pois'].values)\n",
    "        true_poi_indices = instance['true_poi_index'].values if 'true_poi_index' in instance.columns else np.full(len(instance), -1)\n",
    "\n",
    "        seq_len = visits.shape[0]\n",
    "        if seq_len < RAW_SEQ_LEN:\n",
    "            pad_len = RAW_SEQ_LEN - seq_len\n",
    "            visits = np.pad(visits, ((pad_len, 0), (0, 0)), constant_values=PAD)\n",
    "            candidate_pois = np.pad(candidate_pois, ((pad_len, 0), (0, 0)), constant_values=-1)\n",
    "            true_poi_indices = np.pad(true_poi_indices, (pad_len, 0), constant_values=-1)\n",
    "\n",
    "        return {\n",
    "            'visits': torch.tensor(visits, dtype=torch.float),         # Visit features\n",
    "            'candidate_pois': torch.tensor(candidate_pois, dtype=torch.long),  # POI IDs of candidates\n",
    "            'true_poi_indices': torch.tensor(true_poi_indices, dtype=torch.long)  # Index of true POI in candidates\n",
    "        }\n",
    "\n",
    "# Create datasets\n",
    "train_data = POIPredictionDataset(stay_poi_df, train_indices)\n",
    "val_data = POIPredictionDataset(stay_poi_df, val_indices)\n",
    "test_data = POIPredictionDataset(stay_poi_df, test_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
